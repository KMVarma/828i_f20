{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "- cuda/9.0.176\n",
    "- tensorflow==1.12\n",
    "- tensorflow-gpu==1.12\n",
    "- tensorflow-probability==0.5.0\n",
    "- keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.dataset import MNIST\n",
    "from cleverhans.loss import CrossEntropy\n",
    "from cleverhans.train import train\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_keras import cnn_model\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from cleverhans.utils_tf import model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 6\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = .001\n",
    "TRAIN_DIR = 'train_dir'\n",
    "FILENAME = 'mnist.ckpt'\n",
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_tutorial(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                   learning_rate=LEARNING_RATE, train_dir=TRAIN_DIR,\n",
    "                   filename=FILENAME, load_model=LOAD_MODEL,\n",
    "                   testing=False, label_smoothing=0.1):\n",
    "    \"\"\"\n",
    "    MNIST CleverHans tutorial\n",
    "    :param train_start: index of first training set example\n",
    "    :param train_end: index of last training set example\n",
    "    :param test_start: index of first test set example\n",
    "    :param test_end: index of last test set example\n",
    "    :param nb_epochs: number of epochs to train model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param train_dir: Directory storing the saved model\n",
    "    :param filename: Filename to save model under\n",
    "    :param load_model: True for load, False for not load\n",
    "    :param testing: if true, test error is calculated\n",
    "    :param label_smoothing: float, amount of label smoothing for cross entropy\n",
    "    :return: an AccuracyReport object\n",
    "    \"\"\"\n",
    "    tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "    # Object used to keep track of (and return) key accuracies\n",
    "    report = AccuracyReport()\n",
    "\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    if keras.backend.image_data_format() != 'channels_last':\n",
    "        raise NotImplementedError(\"this tutorial requires keras to be configured to channels_last format\")\n",
    "\n",
    "    # Create TF session and set as Keras backend session\n",
    "    sess = tf.Session()\n",
    "    keras.backend.set_session(sess)\n",
    "\n",
    "    # Get MNIST test data\n",
    "    mnist = MNIST(train_start=train_start, train_end=train_end,\n",
    "                  test_start=test_start, test_end=test_end)\n",
    "    x_train, y_train = mnist.get_set('train')\n",
    "    x_test, y_test = mnist.get_set('test')\n",
    "\n",
    "    # Obtain Image Parameters\n",
    "    img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
    "    nb_classes = y_train.shape[1]\n",
    "\n",
    "    # Define input TF placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n",
    "                                        nchannels))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "\n",
    "    # Define TF model graph\n",
    "    model = cnn_model(img_rows=img_rows, img_cols=img_cols,\n",
    "                      channels=nchannels, nb_filters=64,\n",
    "                      nb_classes=nb_classes)\n",
    "    preds = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    def evaluate():\n",
    "        # Evaluate the accuracy of the MNIST model on legitimate test examples\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds, x_test, y_test, args=eval_params)\n",
    "        report.clean_train_clean_eval = acc\n",
    "        #        assert X_test.shape[0] == test_end - test_start, X_test.shape\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % acc)\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "      'nb_epochs': nb_epochs,\n",
    "      'batch_size': batch_size,\n",
    "      'learning_rate': learning_rate,\n",
    "      'train_dir': train_dir,\n",
    "      'filename': filename\n",
    "    }\n",
    "\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.mkdir(train_dir)\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(train_dir)\n",
    "    print(train_dir, ckpt)\n",
    "    ckpt_path = False if ckpt is None else ckpt.model_checkpoint_path\n",
    "    wrap = KerasModelWrapper(model)\n",
    "\n",
    "    if load_model and ckpt_path:\n",
    "        saver = tf.train.Saver()\n",
    "        print(ckpt_path)\n",
    "        saver.restore(sess, ckpt_path)\n",
    "        print(\"Model loaded from: {}\".format(ckpt_path))\n",
    "        evaluate()\n",
    "    else:\n",
    "        print(\"Model was not loaded, training from scratch.\")\n",
    "        loss = CrossEntropy(wrap, smoothing=label_smoothing)\n",
    "        train(sess, loss, x_train, y_train, evaluate=evaluate,\n",
    "              args=train_params, rng=rng)\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds, x_train, y_train, args=eval_params)\n",
    "        report.train_clean_train_clean_eval = acc\n",
    "\n",
    "    # Initialize the Fast Gradient Sign Method (FGSM) attack object and graph\n",
    "    fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "    fgsm_params = {'eps': 0.3,\n",
    "                 'clip_min': 0.,\n",
    "                 'clip_max': 1.}\n",
    "    adv_x = fgsm.generate(x, **fgsm_params)\n",
    "    # Consider the attack to be constant\n",
    "    adv_x = tf.stop_gradient(adv_x)\n",
    "    preds_adv = model(adv_x)\n",
    "\n",
    "    # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "    eval_par = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_adv, x_test, y_test, args=eval_par)\n",
    "    print('Test accuracy on adversarial examples: %0.4f\\n' % acc)\n",
    "    report.clean_train_adv_eval = acc\n",
    "\n",
    "    # Calculating train error\n",
    "    if testing:\n",
    "        eval_par = {'batch_size': batch_size}\n",
    "        acc = model_eval(sess, x, y, preds_adv, x_train,\n",
    "                         y_train, args=eval_par)\n",
    "        report.train_clean_train_adv_eval = acc\n",
    "\n",
    "    print(\"Repeating the process, using adversarial training\")\n",
    "    \n",
    "    # Redefine TF model graph\n",
    "    model_2 = cnn_model(img_rows=img_rows, img_cols=img_cols,\n",
    "                      channels=nchannels, nb_filters=64,\n",
    "                      nb_classes=nb_classes)\n",
    "    wrap_2 = KerasModelWrapper(model_2)\n",
    "    preds_2 = model_2(x)\n",
    "    fgsm2 = FastGradientMethod(wrap_2, sess=sess)\n",
    "\n",
    "    def attack(x):\n",
    "        return fgsm2.generate(x, **fgsm_params)\n",
    "\n",
    "    preds_2_adv = model_2(attack(x))\n",
    "    loss_2 = CrossEntropy(wrap_2, smoothing=label_smoothing, attack=attack)\n",
    "\n",
    "    def evaluate_2():\n",
    "        # Accuracy of adversarially trained model on legitimate test inputs\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, x_test, y_test,\n",
    "                              args=eval_params)\n",
    "        print('Test accuracy on legitimate examples: %0.4f' % accuracy)\n",
    "        report.adv_train_clean_eval = accuracy\n",
    "\n",
    "        # Accuracy of the adversarially trained model on adversarial examples\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, x_test,\n",
    "                              y_test, args=eval_params)\n",
    "        print('Test accuracy on adversarial examples: %0.4f' % accuracy)\n",
    "        report.adv_train_adv_eval = accuracy\n",
    "\n",
    "    # Perform and evaluate adversarial training\n",
    "    train(sess, loss_2, x_train, y_train, evaluate=evaluate_2,\n",
    "        args=train_params, rng=rng)\n",
    "\n",
    "    # Calculate training errors\n",
    "    if testing:\n",
    "        eval_params = {'batch_size': batch_size}\n",
    "        accuracy = model_eval(sess, x, y, preds_2, x_train, y_train,\n",
    "                              args=eval_params)\n",
    "        report.train_adv_train_clean_eval = accuracy\n",
    "        accuracy = model_eval(sess, x, y, preds_2_adv, x_train,\n",
    "                              y_train, args=eval_params)\n",
    "        report.train_adv_train_adv_eval = accuracy\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n",
      "train_dir None\n",
      "Model was not loaded, training from scratch.\n",
      "num_devices:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vulcanscratch/psando/envs/tf-gduap/lib64/python3.6/site-packages/cleverhans/utils_tf.py:511: UserWarning: No GPUS, running on CPU\n",
      "  warnings.warn(\"No GPUS, running on CPU\")\n",
      "/vulcanscratch/psando/envs/tf-gduap/lib64/python3.6/site-packages/cleverhans/utils_tf.py:511: UserWarning: No GPUS, running on CPU\n",
      "  warnings.warn(\"No GPUS, running on CPU\")\n",
      "[INFO 2020-11-11 14:06:36,939 cleverhans] Epoch 0 took 219.30905747413635 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:10:25,042 cleverhans] Epoch 1 took 221.4966471195221 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:14:03,076 cleverhans] Epoch 2 took 211.34212517738342 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:17:43,690 cleverhans] Epoch 3 took 214.3157343864441 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:21:26,310 cleverhans] Epoch 4 took 216.1428029537201 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:25:06,725 cleverhans] Epoch 5 took 214.06298279762268 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9933\n",
      "Test accuracy on adversarial examples: 0.0737\n",
      "\n",
      "Repeating the process, using adversarial training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vulcanscratch/psando/envs/tf-gduap/lib64/python3.6/site-packages/cleverhans/loss.py:41: UserWarning: callable attacks are deprecated, switch to an Attack subclass. callable attacks will not be supported after 2019-05-05.\n",
      "  warnings.warn(\"callable attacks are deprecated, switch to an Attack \"\n",
      "/vulcanscratch/psando/envs/tf-gduap/lib64/python3.6/site-packages/cleverhans/utils_tf.py:511: UserWarning: No GPUS, running on CPU\n",
      "  warnings.warn(\"No GPUS, running on CPU\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_devices:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:34:41,461 cleverhans] Epoch 0 took 533.1717495918274 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9817\n",
      "Test accuracy on adversarial examples: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:44:15,858 cleverhans] Epoch 1 took 534.1897704601288 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9865\n",
      "Test accuracy on adversarial examples: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 14:53:51,366 cleverhans] Epoch 2 took 535.4591963291168 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9885\n",
      "Test accuracy on adversarial examples: 0.8744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 15:03:26,719 cleverhans] Epoch 3 took 535.2267897129059 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9898\n",
      "Test accuracy on adversarial examples: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 15:13:02,014 cleverhans] Epoch 4 took 535.1778798103333 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9903\n",
      "Test accuracy on adversarial examples: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2020-11-11 15:22:37,236 cleverhans] Epoch 5 took 535.1297481060028 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9907\n",
      "Test accuracy on adversarial examples: 0.9225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cleverhans.utils.AccuracyReport at 0x7fa07359a908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_tutorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Train Clean Eval: 0.9933\n",
      "Clean Train Adv Eval: 0.0737\n",
      "Adv Train Clean Eval: 0.9907\n",
      "Adv Train Adv Eval: 0.9225\n"
     ]
    }
   ],
   "source": [
    "accuracy_report = _4\n",
    "print(f\"Clean Train Clean Eval: {accuracy_report.clean_train_clean_eval}\")\n",
    "print(f\"Clean Train Adv Eval: {accuracy_report.clean_train_adv_eval}\")\n",
    "print(f\"Adv Train Clean Eval: {accuracy_report.adv_train_clean_eval}\")\n",
    "print(f\"Adv Train Adv Eval: {accuracy_report.adv_train_adv_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
